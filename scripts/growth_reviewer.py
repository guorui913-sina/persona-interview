#!/usr/bin/env python3
"""
æˆé•¿å›é¡¾ç³»ç»Ÿ - å‘¨æœŸæ€§ç”Ÿæˆæˆé•¿æŠ¥å‘Šï¼Œè¿½è¸ªè¡Œä¸ºæ¨¡å¼å’Œå…³é”®æŒ‡æ ‡

ç‰¹ç‚¹ï¼š
- ä»ç”»åƒä¸­åŠ¨æ€æå–ä¸ªæ€§åŒ–æŒ‡æ ‡ï¼ˆä¸æ˜¯ç¡¬ç¼–ç ï¼‰
- è®¡ç®—é€šç”¨æŒ‡æ ‡ï¼ˆé€‚ç”¨äºæ‰€æœ‰äººï¼‰
- ç”Ÿæˆå‘¨æŠ¥/æœˆæŠ¥
- è¶‹åŠ¿åˆ†æ

ä½¿ç”¨æ–¹æ³•ï¼š
    # ç”Ÿæˆå‘¨æŠ¥
    python growth_reviewer.py weekly --week 5 --persona ../interviews/my-persona.md

    # ç”ŸæˆæœˆæŠ¥
    python growth_reviewer.py monthly --month 2 --persona ../interviews/my-persona.md

    # æŸ¥çœ‹æŒ‡æ ‡è¶‹åŠ¿
    python growth_reviewer.py trends --days 90

    # æå–ç”»åƒä¸­çš„å…ƒæ•°æ®
    python growth_reviewer.py extract-metadata --persona ../interviews/my-persona.md
"""

import sys
import json
import re
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from collections import defaultdict, Counter


def get_decision_dir() -> Path:
    """è·å–å†³ç­–è®°å½•ç›®å½•"""
    script_dir = Path(__file__).parent.parent
    decision_dir = script_dir / "data" / "decisions"
    return decision_dir


def get_review_dir() -> Path:
    """è·å–æˆé•¿å›é¡¾ç›®å½•"""
    script_dir = Path(__file__).parent.parent
    review_dir = script_dir / "data" / "reviews"
    review_dir.mkdir(parents=True, exist_ok=True)
    return review_dir


def load_all_decisions(days: Optional[int] = None) -> List[Dict[str, Any]]:
    """åŠ è½½æ‰€æœ‰å†³ç­–è®°å½•"""
    decision_dir = get_decision_dir()
    decisions = []

    cutoff_date = None
    if days:
        cutoff_date = datetime.now() - timedelta(days=days)

    for file_path in decision_dir.glob("*.json"):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                decision = json.load(f)
                decision_timestamp = datetime.fromisoformat(decision["timestamp"])

                if cutoff_date is None or decision_timestamp >= cutoff_date:
                    decisions.append(decision)
        except Exception as e:
            print(f"âš ï¸  è­¦å‘Šï¼šæ— æ³•åŠ è½½ {file_path.name}: {e}")

    # æŒ‰æ—¶é—´æ’åº
    decisions.sort(key=lambda x: x["timestamp"], reverse=True)
    return decisions


def extract_persona_metadata(persona_path: str) -> Dict[str, Any]:
    """
    ä»ç”»åƒæ–‡ä»¶ä¸­æå–å…ƒæ•°æ®

    æå–å†…å®¹ï¼š
    1. è¡Œä¸ºæ¨¡å¼ï¼ˆbehavioral_patternsï¼‰
    2. ç›²åŒºï¼ˆblind_spotsï¼‰
    3. æ ¸å¿ƒåŠ£åŠ¿ï¼ˆweaknessesï¼‰
    4. å†³ç­–å…³é”®è¯ï¼ˆdecision_keywordsï¼‰
    5. è§¦å‘è¯ï¼ˆtriggersï¼‰
    """
    metadata = {
        "behavioral_patterns": [],
        "blind_spots": [],
        "weaknesses": [],
        "decision_keywords": [],
        "triggers": [],
        "improvement_areas": []
    }

    try:
        with open(persona_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–è¡Œä¸ºæ¨¡å¼
        pattern_section = re.search(r'### è¡Œä¸ºæ¨¡å¼\n+(.*?)(?=\n###|\n##|$)', content, re.DOTALL)
        if pattern_section:
            patterns = re.findall(r'\*\*([\d\.\s]+.*?)\*\*\s*\n', pattern_section.group(1))
            metadata["behavioral_patterns"] = [p.strip() for p in patterns]

        # æå–ç›²åŒº
        blind_section = re.search(r'### ç›²åŒº\n+(.*?)(?=\n---|\n##|$)', content, re.DOTALL)
        if blind_section:
            blinds = re.findall(r'\\d+\\.\\s+\\*\\*(.+?)\\*\\*', blind_section.group(1))
            metadata["blind_spots"] = [b.strip() for b in blinds]

        # æå–æ ¸å¿ƒåŠ£åŠ¿
        weakness_section = re.search(r'## æˆ‘çš„æ ¸å¿ƒåŠ£åŠ¿\n+(.*?)(?=\n---|\n##|$)', content, re.DOTALL)
        if weakness_section:
            weaknesses = re.findall(r'\*\*([\d\.\s]+.+?)\*\*\s+ï¿½?', weakness_section.group(1))
            metadata["weaknesses"] = [w.strip() for w in weaknesses]

        # æå–å†³ç­–å…³é”®è¯ï¼ˆä»"å½“æˆ‘è¯´"æˆ–"å½“æˆ‘è¯´Xæ—¶"ä¸­æå–ï¼‰
        triggers = re.findall(r'å½“(?:æˆ‘)?è¯´"?([^\"]+)"?', content)
        metadata["triggers"] = list(set(triggers))  # å»é‡

        # æå–é«˜é£é™©å…³é”®è¯
        high_risk_keywords = re.findall(r'æåˆ°.*?å…³é”®è¯.*?[:ï¼š]\s*([^\n]+)', content)
        if high_risk_keywords:
            keywords = re.findall(r'["\uff1c]([\u4e00-\u9fa5A-Za-z]+)["\uff1c]', high_risk_keywords[0])
            metadata["decision_keywords"] = keywords

        # æå–æ”¹è¿›é¢†åŸŸï¼ˆä»"å¾…æ”¹è¿›"ã€"éœ€è¦æ”¹è¿›"ç­‰éƒ¨åˆ†ï¼‰
        improvement_patterns = [
            r'\*\*å¾…æ”¹è¿›\*\*[:ï¼š]\s*([^\n]+)',
            r'éœ€è¦æ”¹è¿›[:ï¼š]\s*([^\n]+)',
            r'æ”¹è¿›å»ºè®®[:ï¼š]\s*([^\n]+)'
        ]
        for pattern in improvement_patterns:
            matches = re.findall(pattern, content)
            metadata["improvement_areas"].extend([m.strip() for m in matches])

        print(f"âœ… æˆåŠŸä»ç”»åƒä¸­æå–å…ƒæ•°æ®ï¼š")
        print(f"  - è¡Œä¸ºæ¨¡å¼: {len(metadata['behavioral_patterns'])} ä¸ª")
        print(f"  - ç›²åŒº: {len(metadata['blind_spots'])} ä¸ª")
        print(f"  - æ ¸å¿ƒåŠ£åŠ¿: {len(metadata['weaknesses'])} ä¸ª")
        print(f"  - è§¦å‘è¯: {len(metadata['triggers'])} ä¸ª")
        print(f"  - å†³ç­–å…³é”®è¯: {len(metadata['decision_keywords'])} ä¸ª")

    except Exception as e:
        print(f"âš ï¸  è­¦å‘Šï¼šæ— æ³•ä»ç”»åƒä¸­æå–å…ƒæ•°æ®: {e}")

    return metadata


def calculate_generic_metrics(decisions: List[Dict[str, Any]]) -> Dict[str, Any]:
    """
    è®¡ç®—é€šç”¨æŒ‡æ ‡ï¼ˆé€‚ç”¨äºæ‰€æœ‰äººï¼‰

    é€šç”¨æŒ‡æ ‡ï¼š
    1. å†³ç­–ç±»å‹åˆ†å¸ƒ
    2. æƒ…æ„Ÿå› ç´ ç»Ÿè®¡
    3. é£é™©ç­‰çº§åˆ†å¸ƒ
    4. å†³ç­–ç»“æœçŠ¶æ€
    """
    if not decisions:
        return {}

    metrics = {
        "total_decisions": len(decisions),
        "by_type": defaultdict(int),
        "by_risk": defaultdict(int),
        "emotion_stats": {
            "high_emotion_count": 0,  # æƒ…æ„Ÿå æ¯”>50%
            "avg_emotion_ratio": 0.0,
            "emotion_distribution": []
        },
        "outcome_stats": defaultdict(int)
    }

    emotion_ratios = []

    for decision in decisions:
        # å†³ç­–ç±»å‹ç»Ÿè®¡
        dtype = decision.get("type", "unknown")
        metrics["by_type"][dtype] += 1

        # é£é™©ç­‰çº§ç»Ÿè®¡
        risk = decision.get("risk_level", "unknown")
        metrics["by_risk"][risk] += 1

        # æƒ…æ„Ÿå› ç´ ç»Ÿè®¡
        emotion_ratio = decision.get("emotion_ratio", 0.0)
        emotion_ratios.append(emotion_ratio)
        metrics["emotion_stats"]["emotion_distribution"].append(emotion_ratio)
        if emotion_ratio > 0.5:
            metrics["emotion_stats"]["high_emotion_count"] += 1

        # å†³ç­–ç»“æœç»Ÿè®¡
        outcome = decision.get("outcome", "pending")
        metrics["outcome_stats"][outcome] += 1

    # è®¡ç®—å¹³å‡æƒ…æ„Ÿå æ¯”
    if emotion_ratios:
        metrics["emotion_stats"]["avg_emotion_ratio"] = sum(emotion_ratios) / len(emotion_ratios)

    # è½¬æ¢defaultdictä¸ºæ™®é€šdict
    metrics["by_type"] = dict(metrics["by_type"])
    metrics["by_risk"] = dict(metrics["by_risk"])
    metrics["outcome_stats"] = dict(metrics["outcome_stats"])

    return metrics


def calculate_personalized_metrics(
    decisions: List[Dict[str, Any]],
    persona_metadata: Dict[str, Any]
) -> Dict[str, Any]:
    """
    è®¡ç®—ä¸ªæ€§åŒ–æŒ‡æ ‡ï¼ˆåŸºäºç”»åƒå…ƒæ•°æ®ï¼‰

    ä¸ªæ€§åŒ–æŒ‡æ ‡ï¼š
    1. è§¦å‘è¯å‡ºç°æ¬¡æ•°
    2. è¡Œä¸ºæ¨¡å¼é‡å¤æ£€æµ‹
    3. ç›²åŒºç›¸å…³çš„å†³ç­–
    """
    metrics = {
        "trigger_matches": defaultdict(int),
        "pattern_repetitions": [],
        "blind_spot_violations": defaultdict(int)
    }

    # æå–è§¦å‘è¯
    triggers = persona_metadata.get("triggers", [])
    decision_keywords = persona_metadata.get("decision_keywords", [])

    for decision in decisions:
        description = decision.get("description", "").lower()

        # æ£€æµ‹è§¦å‘è¯
        for trigger in triggers:
            if trigger.lower() in description:
                metrics["trigger_matches"][trigger] += 1

        # æ£€æµ‹å†³ç­–å…³é”®è¯
        for keyword in decision_keywords:
            if keyword.lower() in description:
                metrics["trigger_matches"][keyword] += 1

        # æ£€æµ‹ç›²åŒºç›¸å…³ï¼ˆé«˜é£é™©ä¸”æƒ…æ„Ÿå æ¯”é«˜çš„å†³ç­–ï¼‰
        if decision.get("risk_level") == "high" and decision.get("emotion_ratio", 0) > 0.5:
            blind_spot = "æƒ…æ„ŸåŠ«æŒ"
            metrics["blind_spot_violations"][blind_spot] += 1

    # è½¬æ¢defaultdictä¸ºæ™®é€šdict
    metrics["trigger_matches"] = dict(metrics["trigger_matches"])
    metrics["blind_spot_violations"] = dict(metrics["blind_spot_violations"])

    return metrics


def generate_weekly_report(
    week_num: int,
    persona_path: str,
    start_date: Optional[datetime] = None,
    end_date: Optional[datetime] = None
) -> str:
    """ç”Ÿæˆå‘¨æŠ¥"""
    print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆç¬¬ {week_num} å‘¨æˆé•¿æŠ¥å‘Š...")

    # è®¡ç®—æœ¬å‘¨æ—¥æœŸèŒƒå›´
    if not start_date:
        # å‡è®¾æ¯å‘¨ä»å‘¨ä¸€å¼€å§‹
        today = datetime.now()
        start_of_week = today - timedelta(days=today.weekday())
        start_date = start_of_week - timedelta(weeks=week_num - 1)
        end_date = start_date + timedelta(days=6)

    # åŠ è½½æœ¬å‘¨å†³ç­–
    days_diff = (end_date - start_date).days + 1
    decisions = load_all_decisions(days=days_diff)
    week_decisions = [
        d for d in decisions
        if start_date <= datetime.fromisoformat(d["timestamp"]) <= end_date
    ]

    # æå–ç”»åƒå…ƒæ•°æ®
    persona_metadata = extract_persona_metadata(persona_path)

    # è®¡ç®—æŒ‡æ ‡
    generic_metrics = calculate_generic_metrics(week_decisions)
    personalized_metrics = calculate_personalized_metrics(week_decisions, persona_metadata)

    # ç”ŸæˆæŠ¥å‘Š
    report_lines = [
        f"# æˆé•¿å‘¨æŠ¥ï¼ˆç¬¬{week_num}å‘¨ï¼š{start_date.strftime('%Y-%m-%d')} è‡³ {end_date.strftime('%Y-%m-%d')}ï¼‰\n",
        "## ğŸ“Š å†³ç­–è¿½è¸ª\n",
        f"- **æœ¬å‘¨è®°å½•å†³ç­–**ï¼š{len(week_decisions)} ä¸ª"
    ]

    if generic_metrics:
        report_lines.extend([
            f"- **ç”Ÿå‘½çº§å†³ç­–**ï¼š{generic_metrics['by_type'].get('life_level', 0)} ä¸ª",
            f"- **é‡è¦å†³ç­–**ï¼š{generic_metrics['by_type'].get('important', 0)} ä¸ª",
            f"- **æ—¥å¸¸å†³ç­–**ï¼š{generic_metrics['by_type'].get('daily', 0)} ä¸ª",
            ""
        ])

    # å…·ä½“å†³ç­–åˆ—è¡¨
    if week_decisions:
        report_lines.extend([
            "### æœ¬å‘¨å†³ç­–è¯¦æƒ…\n"
        ])

        for i, decision in enumerate(week_decisions, 1):
            timestamp = datetime.fromisoformat(decision["timestamp"]).strftime("%Y-%m-%d %H:%M")
            dtype = decision.get("type", "unknown")
            risk_level = decision.get("risk_level", "unknown")
            emotion_ratio = decision.get("emotion_ratio", 0.0)
            description = decision.get("description", "")
            emotional_factors = decision.get("emotional_factors", [])
            outcome = decision.get("outcome", "pending")
            decision_id = decision.get("decision_id", "unknown")

            # é£é™©ç­‰çº§æ ‡ç­¾
            risk_emoji = {
                "high": "ğŸ”´",
                "medium": "ğŸŸ¡",
                "low": "ğŸŸ¢"
            }.get(risk_level, "âšª")

            # å†³ç­–ç±»å‹æ ‡ç­¾
            type_label = {
                "life_level": "ç”Ÿå‘½çº§",
                "important": "é‡è¦",
                "daily": "æ—¥å¸¸"
            }.get(dtype, dtype)

            report_lines.extend([
                f"#### {i}. {description}",
                f"- **ID**ï¼š`{decision_id}`",
                f"- **æ—¶é—´**ï¼š{timestamp}",
                f"- **ç±»å‹**ï¼š{type_label} | **é£é™©**ï¼š{risk_emoji} {risk_level.upper()}",
                f"- **æƒ…æ„Ÿå› ç´ **ï¼š{emotion_ratio*100:.0f}%{' (' + ', '.join(emotional_factors) + ')' if emotional_factors else 'æ— '}",
                f"- **çŠ¶æ€**ï¼š{outcome}",
                ""
            ])

    # è¡Œä¸ºæ¨¡å¼åˆ†æ
    report_lines.extend([
        "## ğŸ” è¡Œä¸ºæ¨¡å¼åˆ†æ\n"
    ])

    if personalized_metrics.get("trigger_matches"):
        report_lines.append("**è§¦å‘çš„å…³é”®è¯/æ¨¡å¼**ï¼š")
        for trigger, count in sorted(
            personalized_metrics["trigger_matches"].items(),
            key=lambda x: x[1],
            reverse=True
        ):
            report_lines.append(f"- \"{trigger}\": {count} æ¬¡")
        report_lines.append("")

    if personalized_metrics.get("blind_spot_violations"):
        report_lines.append("**âš ï¸ ç›²åŒºè§¦å‘**ï¼š")
        for blind_spot, count in personalized_metrics["blind_spot_violations"].items():
            report_lines.append(f"- {blind_spot}: {count} æ¬¡")
        report_lines.append("")

    if not personalized_metrics.get("trigger_matches") and not personalized_metrics.get("blind_spot_violations"):
        report_lines.append("âœ… æœ¬å‘¨æ— æ˜æ˜¾è¡Œä¸ºæ¨¡å¼é‡å¤\n")

    # æŒ‡æ ‡è¿½è¸ª
    report_lines.extend([
        "## ğŸ“ˆ æŒ‡æ ‡è¿½è¸ª\n",
        "| æŒ‡æ ‡ | æœ¬å‘¨ | è¯´æ˜ |",
        "|------|------|------|"
    ])

    if generic_metrics:
        total = generic_metrics.get("total_decisions", 0)
        high_emotion = generic_metrics.get("emotion_stats", {}).get("high_emotion_count", 0)
        avg_emotion = generic_metrics.get("emotion_stats", {}).get("avg_emotion_ratio", 0.0)

        emotion_hijack_rate = (high_emotion / total * 100) if total > 0 else 0

        report_lines.extend([
            f"| å†³ç­–æ€»æ•° | {total} | æœ¬å‘¨è®°å½•çš„å†³ç­–æ•°é‡ |",
            f"| é«˜æƒ…æ„Ÿå†³ç­– | {high_emotion} ({emotion_hijack_rate:.0f}%) | æƒ…æ„Ÿå æ¯”>50%çš„å†³ç­– |",
            f"| å¹³å‡æƒ…æ„Ÿå æ¯” | {avg_emotion*100:.0f}% | æ‰€æœ‰å†³ç­–çš„å¹³å‡æƒ…æ„Ÿå› ç´  |"
        ])

    # ç”»åƒå¯¹æ¯”
    report_lines.extend([
        "",
        "## ğŸ¯ ç”»åƒå¯¹æ¯”\n"
    ])

    if persona_metadata.get("behavioral_patterns"):
        report_lines.append("**å¯¹æ¯”ç”»åƒä¸­çš„è¡Œä¸ºæ¨¡å¼**ï¼š")
        for i, pattern in enumerate(persona_metadata["behavioral_patterns"][:3], 1):
            report_lines.append(f"{i}. {pattern}")
        report_lines.append("")

    if persona_metadata.get("blind_spots"):
        report_lines.append("**å¯¹æ¯”ç”»åƒä¸­çš„ç›²åŒº**ï¼š")
        for i, blind in enumerate(persona_metadata["blind_spots"][:3], 1):
            report_lines.append(f"{i}. {blind}")
        report_lines.append("")

    # ä¸‹å‘¨å»ºè®®
    report_lines.extend([
        "## ğŸ’¡ ä¸‹å‘¨å»ºè®®\n"
    ])

    suggestions = []

    if generic_metrics and generic_metrics.get("emotion_stats", {}).get("high_emotion_count", 0) > 0:
        suggestions.append("1. åŠ å¼ºå†·é™æœŸæ‰§è¡Œï¼šé‡å¤§å†³ç­–å‰è‡³å°‘å†·é™2-3å¤©")

    if personalized_metrics.get("trigger_matches"):
        top_trigger = max(
            personalized_metrics["trigger_matches"].items(),
            key=lambda x: x[1]
        )
        suggestions.append(f"2. æ³¨æ„è§¦å‘è¯ï¼š\"{top_trigger[0]}\" å‡ºç° {top_trigger[1]} æ¬¡ï¼Œå†³ç­–å‰å…ˆåšé£é™©è¯„ä¼°")

    if generic_metrics and generic_metrics.get("by_risk", {}).get("high", 0) > 0:
        suggestions.append("3. é«˜é£é™©å†³ç­–ç®¡ç†ï¼šç¡®ä¿å®Œæˆæ‰€æœ‰å¿…è¦è¡ŒåŠ¨ï¼ˆåˆ—å‡ºåå¯¹ç†ç”±ã€å’¨è¯¢ä»–äººã€æœ€åæƒ…å†µæ¨æ¼”ï¼‰")

    if not suggestions:
        suggestions.append("ç»§ç»­ä¿æŒç†æ€§å†³ç­–çš„ä¹ æƒ¯ï¼")

    report_lines.extend(suggestions)
    report_lines.append("")
    report_lines.append("---")
    report_lines.append(f"\n**ç”Ÿæˆæ—¶é—´**ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}")

    return "\n".join(report_lines)


def save_report(report: str, report_type: str, identifier: int) -> Path:
    """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
    review_dir = get_review_dir()

    timestamp = datetime.now().strftime("%Y%m%d")
    filename = f"{report_type}_{identifier}_{timestamp}.md"
    file_path = review_dir / filename

    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(report)

    return file_path


def main():
    import argparse

    parser = argparse.ArgumentParser(description="æˆé•¿å›é¡¾ç³»ç»Ÿ")
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # weeklyå‘½ä»¤
    weekly_parser = subparsers.add_parser("weekly", help="ç”Ÿæˆå‘¨æŠ¥")
    weekly_parser.add_argument("--week", type=int, required=True, help="å‘¨æ•°")
    weekly_parser.add_argument("--persona", required=True, help="ç”»åƒæ–‡ä»¶è·¯å¾„")

    # monthlyå‘½ä»¤
    monthly_parser = subparsers.add_parser("monthly", help="ç”ŸæˆæœˆæŠ¥")
    monthly_parser.add_argument("--month", type=int, required=True, help="æœˆæ•°")
    monthly_parser.add_argument("--persona", required=True, help="ç”»åƒæ–‡ä»¶è·¯å¾„")

    # trendså‘½ä»¤
    trends_parser = subparsers.add_parser("trends", help="æŸ¥çœ‹æŒ‡æ ‡è¶‹åŠ¿")
    trends_parser.add_argument("--days", type=int, default=90, help="æŸ¥çœ‹æœ€è¿‘å¤šå°‘å¤©")

    # extract-metadataå‘½ä»¤
    metadata_parser = subparsers.add_parser("extract-metadata", help="æå–ç”»åƒå…ƒæ•°æ®")
    metadata_parser.add_argument("--persona", required=True, help="ç”»åƒæ–‡ä»¶è·¯å¾„")

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        sys.exit(1)

    try:
        if args.command == "weekly":
            report = generate_weekly_report(
                week_num=args.week,
                persona_path=args.persona
            )
            file_path = save_report(report, "weekly", args.week)
            print(f"\nâœ… å‘¨æŠ¥å·²ä¿å­˜åˆ°ï¼š{file_path}")

        elif args.command == "monthly":
            print(f"ğŸ“Š æ­£åœ¨ç”Ÿæˆç¬¬ {args.month} æœˆæˆé•¿æŠ¥å‘Š...")
            # TODO: å®ç°æœˆæŠ¥ç”Ÿæˆ
            print("âš ï¸  æœˆæŠ¥åŠŸèƒ½å¼€å‘ä¸­...")

        elif args.command == "trends":
            print(f"ğŸ“ˆ æŸ¥çœ‹æœ€è¿‘ {args.days} å¤©çš„æŒ‡æ ‡è¶‹åŠ¿...")
            decisions = load_all_decisions(days=args.days)
            metrics = calculate_generic_metrics(decisions)

            print(f"\næ€»å†³ç­–æ•°ï¼š{metrics.get('total_decisions', 0)}")
            print(f"å†³ç­–ç±»å‹åˆ†å¸ƒï¼š{metrics.get('by_type', {})}")
            print(f"é£é™©ç­‰çº§åˆ†å¸ƒï¼š{metrics.get('by_risk', {})}")

        elif args.command == "extract-metadata":
            print(f"\nğŸ“‹ æ­£åœ¨æå–ç”»åƒå…ƒæ•°æ®...")
            metadata = extract_persona_metadata(args.persona)

            print(f"\nå…ƒæ•°æ®ï¼š")
            print(json.dumps(metadata, indent=2, ensure_ascii=False))

    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
