#!/usr/bin/env python3
"""
ç®€å†è§£æå™¨ - ä»ç®€å†ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯

æ”¯æŒæ ¼å¼ï¼šPDF, DOCX, Markdown
è¾“å‡ºæ ¼å¼ï¼šJSON

ä½¿ç”¨æ–¹æ³•ï¼š
    python resume_parser.py resume.pdf
    python resume_parser.py resume.docx
    python resume_parser.py resume.md
"""

import sys
import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List


def parse_markdown(file_path: str) -> str:
    """è§£æ Markdown æ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return f.read()


def parse_docx(file_path: str) -> str:
    """è§£æ DOCX æ–‡ä»¶"""
    try:
        from docx import Document
        doc = Document(file_path)
        return '\n'.join([para.text for para in doc.paragraphs])
    except ImportError:
        print("é”™è¯¯ï¼šéœ€è¦å®‰è£… python-docx")
        print("è¯·è¿è¡Œï¼špip install python-docx")
        sys.exit(1)


def parse_pdf(file_path: str) -> str:
    """è§£æ PDF æ–‡ä»¶"""
    try:
        import PyPDF2
        with open(file_path, 'rb') as f:
            reader = PyPDF2.PdfReader(f)
            text = ''
            for page in reader.pages:
                text += page.extract_text()
        return text
    except ImportError:
        print("é”™è¯¯ï¼šéœ€è¦å®‰è£… PyPDF2")
        print("è¯·è¿è¡Œï¼špip install PyPDF2")
        sys.exit(1)


def parse_resume(file_path: str) -> str:
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åé€‰æ‹©è§£ææ–¹æ³•"""
    path = Path(file_path)

    if not path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")

    suffix = path.suffix.lower()

    if suffix == '.md' or suffix == '.markdown':
        return parse_markdown(file_path)
    elif suffix == '.docx':
        return parse_docx(file_path)
    elif suffix == '.pdf':
        return parse_pdf(file_path)
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼š{suffix}")


def extract_resume_info(text: str) -> Dict[str, Any]:
    """
    ä½¿ç”¨è§„åˆ™å’Œæ­£åˆ™è¡¨è¾¾å¼ä»ç®€å†æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯

    è¿™æ˜¯ä¸€ä¸ªåŸºç¡€å®ç°ã€‚å¯¹äºæ›´å‡†ç¡®çš„æå–ï¼Œå»ºè®®ä½¿ç”¨ LLM APIã€‚
    """

    info = {
        "raw_text": text,
        "extracted_at": datetime.now().isoformat(),
        "basics": {},
        "work_history": [],
        "education": [],
        "skills": [],
        "projects": []
    }

    lines = text.split('\n')
    current_section = None

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # è¯†åˆ«ç« èŠ‚æ ‡é¢˜ï¼ˆç®€å•è§„åˆ™ï¼šå¸¸è§æ ‡é¢˜ï¼‰
        if any(keyword in line for keyword in ['å·¥ä½œç»å†', 'å·¥ä½œä½“éªŒ', 'ç»å†', 'Work Experience', 'Experience']):
            current_section = 'work'
            continue
        elif any(keyword in line for keyword in ['æ•™è‚²', 'å­¦å†', 'Education']):
            current_section = 'education'
            continue
        elif any(keyword in line for keyword in ['æŠ€èƒ½', 'ä¸“é•¿', 'Skills', 'æŠ€æœ¯æ ˆ']):
            current_section = 'skills'
            continue
        elif any(keyword in line for keyword in ['é¡¹ç›®', 'Project', 'Projects']):
            current_section = 'projects'
            continue

        # æå–ä¿¡æ¯ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”ç”¨ä¸­å»ºè®®ç”¨ LLMï¼‰
        if current_section == 'work':
            # ç®€å•çš„æå–ï¼šå‡è®¾æ ¼å¼ä¸º "å…¬å¸ èŒä½ æ—¶é—´"
            parts = line.split()
            if len(parts) >= 2:
                info["work_history"].append({
                    "company": parts[0],
                    "position": parts[1] if len(parts) > 1 else "",
                    "description": line
                })
        elif current_section == 'skills':
            # åˆ†å‰²æŠ€èƒ½åˆ—è¡¨
            skills = re.split(r'[,ã€|]', line)
            info["skills"].extend([s.strip() for s in skills if s.strip()])

    # å°è¯•æå–åŸºæœ¬ä¿¡æ¯ï¼ˆåå­—ã€é‚®ç®±ã€ç”µè¯ï¼‰
    # é‚®ç®±
    email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    emails = re.findall(email_pattern, text)
    if emails:
        info["basics"]["email"] = emails[0]

    # ç”µè¯ï¼ˆç®€å•åŒ¹é…ï¼‰
    phone_pattern = r'1[3-9]\d{9}'
    phones = re.findall(phone_pattern, text)
    if phones:
        info["basics"]["phone"] = phones[0]

    return info


def save_json(data: Dict[str, Any], output_path: str):
    """ä¿å­˜ä¸º JSON æ–‡ä»¶"""
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²ä¿å­˜åˆ°ï¼š{output_path}")


def main():
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•ï¼š")
        print("  python resume_parser.py <resume_file>")
        print("\nç¤ºä¾‹ï¼š")
        print("  python resume_parser.py resume.pdf")
        print("  python resume_parser.py resume.docx")
        print("  python resume_parser.py resume.md")
        sys.exit(1)

    resume_file = sys.argv[1]

    try:
        # 1. è§£æç®€å†
        print(f"ğŸ“„ æ­£åœ¨è§£æï¼š{resume_file}")
        text = parse_resume(resume_file)
        print(f"âœ… è§£ææˆåŠŸï¼Œå…± {len(text)} ä¸ªå­—ç¬¦")

        # 2. æå–ä¿¡æ¯
        print("ğŸ” æ­£åœ¨æå–å…³é”®ä¿¡æ¯...")
        info = extract_resume_info(text)

        # 3. ä¿å­˜ç»“æœ
        output_file = Path(resume_file).stem + "_parsed.json"
        save_json(info, output_file)

        # 4. æ˜¾ç¤ºæ‘˜è¦
        print("\nğŸ“Š æå–æ‘˜è¦ï¼š")
        print(f"  - é‚®ç®±ï¼š{info['basics'].get('email', 'æœªæ‰¾åˆ°')}")
        print(f"  - ç”µè¯ï¼š{info['basics'].get('phone', 'æœªæ‰¾åˆ°')}")
        print(f"  - å·¥ä½œç»å†ï¼š{len(info['work_history'])} æ¡")
        print(f"  - æŠ€èƒ½ï¼š{len(info['skills'])} é¡¹")

        # æç¤ºï¼šå»ºè®®ä½¿ç”¨ LLM è¿›è¡Œæ›´å‡†ç¡®çš„æå–
        print("\nğŸ’¡ æç¤ºï¼šå½“å‰ä½¿ç”¨è§„åˆ™æå–ï¼Œå»ºè®®ç»“åˆ LLM API è¿›è¡Œæ›´å‡†ç¡®çš„è§£æ")
        print("   å¯ä»¥ä½¿ç”¨ Claude APIã€OpenAI API ç­‰å¢å¼ºæå–æ•ˆæœ")

    except Exception as e:
        print(f"âŒ é”™è¯¯ï¼š{e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
